{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the model...\n",
      "\n",
      " \n",
      " \n",
      " \n",
      "    CHAT:     \n",
      " \n",
      "\n",
      "computer: hi ! please type your name.\n",
      "\n",
      "user: John\n",
      "computer: hi , John ! My name is john.\n",
      "\n",
      "computer:  my neighbor has three kids , a living in which  .    (with probability of 0.000471)\n",
      "computer:  a two hundred that will have a good house .     (with probability of 0.004241)\n",
      "computer:  he would yet .     (with probability of 0.117518)\n",
      "computer:  she is at home .     (with probability of 0.262594)\n",
      "computer:  yes , but i have a puppy , but i am looking for another bag on it .     (with probability of 0.000016)\n",
      "computer:  yes , i do .     (with probability of 0.184180)\n",
      "computer:  well , if i have a big test , either to me .     (with probability of 0.007713)\n",
      "computer:  i sometimes visit my sister .     (with probability of 0.026642)\n",
      "computer:  yes , i do .     (with probability of 0.650533)\n",
      "computer:  my family watches it together .     (with probability of 0.490357)\n",
      "computer:  i usually bring my and .     (with probability of 0.009541)\n",
      "computer:  i usually have a picnic in the .     (with probability of 0.072904)\n",
      "computer:  well , my favorite piece of clothes is , , and all in .     (with probability of 0.003010)\n",
      "computer:  every morning , i sometimes walk down late .     (with probability of 0.006939)\n",
      "computer:  i switched my food .     (with probability of 0.017661)\n",
      "computer:  i am pleased to get sick .     (with probability of 0.003751)\n",
      "computer:  yes , i am not well food .     (with probability of 0.054070)\n",
      "computer:  yes , but i had a car problem .     (with probability of 0.027602)\n",
      "computer:  well , there are many such as death valley in the country .     (with probability of 0.041042)\n",
      "computer:  yes , a little beer , , and many .     (with probability of 0.006010)\n",
      "computer:  i usually read politics to music .     (with probability of 0.091965)\n",
      "computer:  the and the street .     (with probability of 0.001126)\n",
      "computer:  i prefer writing paper letters .     (with probability of 0.073335)\n",
      "computer:  oh , no . i call it to my daughter .     (with probability of 0.001528)\n",
      "computer:  oh , look ! i have been in the world around the world .     (with probability of 0.003764)\n",
      "computer:  yes , i took it 6 years ago .     (with probability of 0.032703)\n",
      "computer:  only two days .     (with probability of 0.161200)\n",
      "computer:  no , my area in the park .     (with probability of 0.042497)\n",
      "computer:  they come in the park near the world .     (with probability of 0.005388)\n",
      "computer:  i usually get up my neighbors .     (with probability of 0.093004)\n",
      "computer:  i am a big fan of and i have to make with in the .     (with probability of 0.000811)\n",
      "computer:  yes , i am sure i have to go to the bathroom .     (with probability of 0.006977)\n",
      "computer:  not really , but i traveled to the local people .     (with probability of 0.014345)\n",
      "computer:  we sometimes do .     (with probability of 0.033413)\n",
      "computer:  i am not sure .     (with probability of 0.094828)\n",
      "computer:  only two days .     (with probability of 0.158154)\n",
      "computer:  it usually gets here at noon .     (with probability of 0.017149)\n",
      "computer:  i have no idea , but when i traveled to my friends , too .     (with probability of 0.000120)\n",
      "computer:  i wash a t shirt when hanging out with a while .     (with probability of 0.010242)\n",
      "computer:  i have been in a hurry .     (with probability of 0.019183)\n",
      "computer:  there are many .     (with probability of 0.047790)\n",
      "computer:  well , it is just black ink on a business .     (with probability of 0.040327)\n",
      "computer:  oh , no . i am in english .     (with probability of 0.029908)\n",
      "computer:  i think my first language spoken and a .     (with probability of 0.000444)\n",
      "computer:  well , taking a , and history everything should be given to approach anytime and anywhere .     (with probability of 0.000058)\n",
      "computer:  yes , but i was late and sunny every day .     (with probability of 0.033558)\n",
      "computer:  i got laid off .     (with probability of 0.311061)\n",
      "computer:  a man left ago .     (with probability of 0.124626)\n",
      "computer:  he landed the plane and walked on the hood .     (with probability of 0.021202)\n",
      "computer:  yes , we do .     (with probability of 0.271474)\n",
      "computer:  yes , i do .     (with probability of 0.151845)\n",
      "computer:  no , it was on the plane .     (with probability of 0.062347)\n",
      "computer:  no , the injury was not really serious .     (with probability of 0.519900)\n",
      "computer:  yes , i do . i always keep it in my purse .     (with probability of 0.833866)\n",
      "computer:  that means it is hard for traffic .     (with probability of 0.009455)\n",
      "computer:  yes , i did . i enjoyed playing hide and seek with my .     (with probability of 0.047836)\n",
      "computer:  i do not know anyone .     (with probability of 0.085984)\n",
      "computer:  yes , i did .     (with probability of 0.797856)\n",
      "computer:  i was with my beloved family .     (with probability of 0.952033)\n",
      "computer:  i dreamed of being a fashion .     (with probability of 0.797361)\n",
      "computer:  i loved my mom the most since she was always there and took care of me .     (with probability of 0.570022)\n",
      "computer:  robin hood , he took money from the rich and gave it to the poor .     (with probability of 0.422572)\n",
      "computer:  green rice fields which i happen to see everywhere remind me of my beautiful childhood .     (with probability of 0.646218)\n",
      "computer:  yes , of course . i am more mature now both physically and mentally .     (with probability of 0.752448)\n",
      "computer:  because it people into who they will become .     (with probability of 0.704746)\n",
      "computer:  there are 6 rooms : a living room , 2 , a bathroom and a kitchen .     (with probability of 0.700155)\n",
      "computer:  my bedroom is on the first floor of a three house .     (with probability of 0.903142)\n",
      "computer:  it is not very , just enough to put necessary furniture in .     (with probability of 0.658530)\n",
      "computer:  it is painted pink pink , my favorite color .     (with probability of 0.668693)\n",
      "computer:  i love it very much because it is my private space whenever i go home .     (with probability of 0.498404)\n",
      "computer:  my family it on a bed , so .     (with probability of 0.032381)\n",
      "computer:  just yesterday , i am afraid the students are out on the road .     (with probability of 0.000355)\n",
      "computer:  about 10 hours .     (with probability of 0.056229)\n",
      "computer:  no , everyone in my family .     (with probability of 0.422063)\n",
      "computer:  there are many such as death valley , falls , the , and the grand canyon , are recommended .     (with probability of 0.002145)\n",
      "computer:  a friend gave a to her .     (with probability of 0.006233)\n",
      "computer:  my family watches it together .     (with probability of 0.202242)\n",
      "computer:  i loved my in a waitress .     (with probability of 0.027371)\n",
      "computer:  well , i would never buy lunch .     (with probability of 0.007111)\n",
      "computer:  i gave him to my .     (with probability of 0.034829)\n",
      "computer:  some special , , graduation , new year is , , etc .     (with probability of 0.015552)\n",
      "computer:  my mom , i bought her a coat on a business trip to .     (with probability of 0.531796)\n",
      "computer:  yes , it is . it is one of the best ways to show your love and gratitude to someone .     (with probability of 0.458908)\n",
      "computer:  well , historical places are always my first choice when traveling .     (with probability of 0.707806)\n",
      "computer:  i usually listen to the tour guide the and take notes about important historical events .     (with probability of 0.351588)\n",
      "computer:  whenever i travel to a foreign country in the , in england and in india .     (with probability of 0.014157)\n",
      "computer:  i like the in the , and the in and .     (with probability of 0.000854)\n",
      "computer:  i think there are nearly miles in world .     (with probability of 0.009459)\n",
      "computer:  thanks to me step to see a eye in a .     (with probability of 0.000256)\n",
      "computer:  it is located in the capital of , in .     (with probability of 0.211900)\n",
      "computer:  sure . nowadays the youth should visit these kind of places more often in order to preserve historical and values of their country .     (with probability of 0.139477)\n",
      "computer:  i am taking a to get a better one job for me to get married with .     (with probability of 0.000002)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer:  oh , look ! i have to send this check .     (with probability of 0.000050)\n",
      "computer:  i came a plane in the morning .     (with probability of 0.011822)\n",
      "computer:  i usually read politics the clothes . i just keep reading books while the color .     (with probability of 0.000514)\n",
      "computer:  my favorite is .     (with probability of 0.073862)\n",
      "computer:  oh , no more . i can not keep online .     (with probability of 0.001035)\n",
      "computer:  i only buy a newspaper , so it does not cost much money .     (with probability of 0.095328)\n",
      "computer:  i think the best is for the news .     (with probability of 0.014931)\n",
      "computer:  yes , unfortunately it is just a matter of time .     (with probability of 0.292288)\n",
      "computer:  i hate the beautiful photos .     (with probability of 0.041622)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, RepeatVector, Dropout, merge\n",
    "from keras.optimizers import Adam \n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import concatenate\n",
    "\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "np.random.seed(1234)  # for reproducibility\n",
    "import pickle as cPickle\n",
    "#import theano\n",
    "import os.path\n",
    "import sys\n",
    "import nltk\n",
    "import re\n",
    "import time\n",
    "\n",
    "from keras.utils import plot_model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "word_embedding_size = 100\n",
    "sentence_embedding_size = 300\n",
    "dictionary_size = 7000\n",
    "maxlen_input = 50\n",
    "\n",
    "vocabulary_file = 'vocabulary_movie'\n",
    "weights_file = 'my_model_weights20.h5'\n",
    "unknown_token = 'something'\n",
    "file_saved_context = 'saved_context'\n",
    "file_saved_answer = 'saved_answer'\n",
    "name_of_computer = 'john'\n",
    "\n",
    "def greedy_decoder(input):\n",
    "\n",
    "    flag = 0\n",
    "    prob = 1\n",
    "    ans_partial = np.zeros((1,maxlen_input))\n",
    "    ans_partial[0, -1] = 2  #  the index of the symbol BOS (begin of sentence)\n",
    "    for k in range(maxlen_input - 1):\n",
    "        ye = model.predict([input, ans_partial])\n",
    "        yel = ye[0,:]\n",
    "        p = np.max(yel)\n",
    "        mp = np.argmax(ye)\n",
    "        ans_partial[0, 0:-1] = ans_partial[0, 1:]\n",
    "        ans_partial[0, -1] = mp\n",
    "        if mp == 3:  #  he index of the symbol EOS (end of sentence)\n",
    "            flag = 1\n",
    "        if flag == 0:    \n",
    "            prob = prob * p\n",
    "    text = ''\n",
    "    for k in ans_partial[0]:\n",
    "        k = k.astype(int)\n",
    "        if k < (dictionary_size-2):\n",
    "            w = vocabulary[k]\n",
    "            text = text + w[0] + ' '\n",
    "    return(text, prob)\n",
    "    \n",
    "    \n",
    "def preprocess(raw_word, name):\n",
    "    \n",
    "    l1 = ['won’t','won\\'t','wouldn’t','wouldn\\'t','’m', '’re', '’ve', '’ll', '’s','’d', 'n’t', '\\'m', '\\'re', '\\'ve', '\\'ll', '\\'s', '\\'d', 'can\\'t', 'n\\'t', 'B: ', 'A: ', ',', ';', '.', '?', '!', ':', '. ?', ',   .', '. ,', 'EOS', 'BOS', 'eos', 'bos']\n",
    "    l2 = ['will not','will not','would not','would not',' am', ' are', ' have', ' will', ' is', ' had', ' not', ' am', ' are', ' have', ' will', ' is', ' had', 'can not', ' not', '', '', ' ,', ' ;', ' .', ' ?', ' !', ' :', '? ', '.', ',', '', '', '', '']\n",
    "    l3 = ['-', '_', ' *', ' /', '* ', '/ ', '\\\"', ' \\\\\"', '\\\\ ', '--', '...', '. . .']\n",
    "    l4 = ['jeffrey','fred','benjamin','paula','walter','rachel','andy','helen','harrington','kathy','ronnie','carl','annie','cole','ike','milo','cole','rick','johnny','loretta','cornelius','claire','romeo','casey','johnson','rudy','stanzi','cosgrove','wolfi','kevin','paulie','cindy','paulie','enzo','mikey','i\\97','davis','jeffrey','norman','johnson','dolores','tom','brian','bruce','john','laurie','stella','dignan','elaine','jack','christ','george','frank','mary','amon','david','tom','joe','paul','sam','charlie','bob','marry','walter','james','jimmy','michael','rose','jim','peter','nick','eddie','johnny','jake','ted','mike','billy','louis','ed','jerry','alex','charles','tommy','bobby','betty','sid','dave','jeffrey','jeff','marty','richard','otis','gale','fred','bill','jones','smith','mickey']    \n",
    "\n",
    "    raw_word = raw_word.lower()\n",
    "    raw_word = raw_word.replace(', ' + name_of_computer, '')\n",
    "    raw_word = raw_word.replace(name_of_computer + ' ,', '')\n",
    "\n",
    "    for j, term in enumerate(l1):\n",
    "        raw_word = raw_word.replace(term,l2[j])\n",
    "        \n",
    "    for term in l3:\n",
    "        raw_word = raw_word.replace(term,' ')\n",
    "    \n",
    "    for term in l4:\n",
    "        raw_word = raw_word.replace(', ' + term, ', ' + name)\n",
    "        raw_word = raw_word.replace(' ' + term + ' ,' ,' ' + name + ' ,')\n",
    "        raw_word = raw_word.replace('i am ' + term, 'i am ' + name_of_computer)\n",
    "        raw_word = raw_word.replace('my name is' + term, 'my name is ' + name_of_computer)\n",
    "    \n",
    "    for j in range(30):\n",
    "        raw_word = raw_word.replace('. .', '')\n",
    "        raw_word = raw_word.replace('.  .', '')\n",
    "        raw_word = raw_word.replace('..', '')\n",
    "       \n",
    "    for j in range(5):\n",
    "        raw_word = raw_word.replace('  ', ' ')\n",
    "    \n",
    "    if raw_word[-1] !=  '!' and raw_word[-1] != '?' and raw_word[-1] != '.' and raw_word[-2:] !=  '! ' and raw_word[-2:] != '? ' and raw_word[-2:] != '. ' :\n",
    "        raw_word = raw_word + ' .'\n",
    "    \n",
    "    if raw_word == ' !' or raw_word == ' ?' or raw_word == ' .' or raw_word == ' ! ' or raw_word == ' ? ' or raw_word == ' . ':\n",
    "        raw_word = 'what ?'\n",
    "    \n",
    "    if raw_word == '  .' or raw_word == ' .' or raw_word == '  . ':\n",
    "        raw_word = 'i do not want to talk about it .'\n",
    "      \n",
    "    return raw_word\n",
    "\n",
    "def tokenize(sentences):\n",
    "\n",
    "    # Tokenizing the sentences into words:\n",
    "    tokenized_sentences = nltk.word_tokenize(sentences)\n",
    "    index_to_word = [x[0] for x in vocabulary]\n",
    "    word_to_index = dict([(w,i) for i,w in enumerate(index_to_word)])\n",
    "    tokenized_sentences = [w if w in word_to_index else unknown_token for w in tokenized_sentences]\n",
    "    X = np.asarray([word_to_index[w] for w in tokenized_sentences])\n",
    "    s = X.size\n",
    "    Q = np.zeros((1,maxlen_input))\n",
    "    if s < (maxlen_input + 1):\n",
    "        Q[0,- s:] = X\n",
    "    else:\n",
    "        Q[0,:] = X[- maxlen_input:]\n",
    "    \n",
    "    return Q\n",
    "\n",
    " # Open files to save the conversation for further training:\n",
    "qf = open(file_saved_context, 'w')\n",
    "af = open(file_saved_answer, 'w')\n",
    "\n",
    "print('Starting the model...')\n",
    "\n",
    "# *******************************************************************\n",
    "# Keras model of the chatbot: \n",
    "# *******************************************************************\n",
    "\n",
    "ad = Adam(lr=0.00005) \n",
    "\n",
    "input_context = Input(shape=(maxlen_input,), dtype='int32')\n",
    "input_answer = Input(shape=(maxlen_input,), dtype='int32')\n",
    "LSTM_encoder = LSTM(sentence_embedding_size, kernel_initializer= 'lecun_uniform')\n",
    "LSTM_decoder = LSTM(sentence_embedding_size, kernel_initializer= 'lecun_uniform')\n",
    "if os.path.isfile(weights_file):\n",
    "    Shared_Embedding = Embedding(output_dim=word_embedding_size, input_dim=dictionary_size, input_length=maxlen_input, name='Shared')\n",
    "else:\n",
    "    Shared_Embedding = Embedding(output_dim=word_embedding_size, input_dim=dictionary_size, weights=[embedding_matrix], input_length=maxlen_input, name='Shared')\n",
    "word_embedding_context = Shared_Embedding(input_context)\n",
    "context_embedding = LSTM_encoder(word_embedding_context)\n",
    "\n",
    "word_embedding_answer = Shared_Embedding(input_answer)\n",
    "answer_embedding = LSTM_decoder(word_embedding_answer)\n",
    "\n",
    "merge_layer = concatenate([context_embedding, answer_embedding], axis=1)\n",
    "out = Dense(int(dictionary_size/2), activation=\"relu\")(merge_layer)\n",
    "out = Dense(dictionary_size, activation=\"softmax\")(out)\n",
    "\n",
    "model = Model(inputs=[input_context, input_answer], outputs = [out])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=ad)\n",
    "\n",
    "#plot_model(model, to_file='model_graph.png')    \n",
    "\n",
    "if os.path.isfile(weights_file):\n",
    "    model.load_weights(weights_file)\n",
    "\n",
    "\n",
    "# Loading the data:\n",
    "vocabulary = cPickle.load(open(vocabulary_file, 'rb'))\n",
    "\n",
    "print(\"\\n \\n \\n \\n    CHAT:     \\n \\n\")\n",
    "\n",
    "# Processing the user query:\n",
    "prob = 0\n",
    "que = ''\n",
    "last_query  = ' '\n",
    "last_last_query = ''\n",
    "text = ' '\n",
    "last_text = ''\n",
    "print('computer: hi ! please type your name.\\n')\n",
    "name = input('user: ')\n",
    "print('computer: hi , ' + name +' ! My name is ' + name_of_computer + '.\\n') \n",
    "g = open(\"test_data_100\",'r').read()\n",
    "test_data = g.split('\\n')\n",
    "i=0\n",
    "while que != 'exit .':\n",
    "    \n",
    "    que = test_data[i]\n",
    "    que = preprocess(que, name_of_computer)\n",
    "    # Collecting data for training:\n",
    "    q = last_query + ' ' + text\n",
    "    a = que\n",
    "    # Composing the context:\n",
    "    if prob > 0.2:\n",
    "        query = text + ' ' + que\n",
    "    else:    \n",
    "        query = que\n",
    "   \n",
    "    last_text = text\n",
    "    \n",
    "    Q = tokenize(query)\n",
    "    \n",
    "    # Using the trained model to predict the answer:\n",
    "    \n",
    "    predout, prob = greedy_decoder(Q[0:1])\n",
    "    start_index = predout.find('EOS')\n",
    "    text = preprocess(predout[0:start_index], name)\n",
    "    print ('computer: ' + text + '    (with probability of %f)'%prob)\n",
    "    qf.write(que + '\\n')\n",
    "    af.write(text + '\\n')\n",
    "    last_last_query = last_query    \n",
    "    last_query = que\n",
    "    i+=2\n",
    "qf.close()\n",
    "af.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
